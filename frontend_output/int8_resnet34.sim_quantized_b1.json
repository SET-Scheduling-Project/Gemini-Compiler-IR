{
   "src_quantize_1_1": {
      "layer_index": 0,
      "name": "src_quantize_1_1",
      "operation": "quantize",
      "device": "npu",
      "input_dtype": [
         "float16"
      ],
      "output_dtype": [
         "int8"
      ],
      "input_shape": [
         [
            1,
            3,
            224,
            224
         ]
      ],
      "output_shape": [
         [
            1,
            3,
            224,
            224
         ]
      ],
      "file_list": {
         "input_activation1": "src_quantize_1_1_input_activation1.npy",
         "output_activation1": "src_quantize_1_1_output_activation1.npy"
      },
      "previous_layer": [
         "input1"
      ],
      "next_layer": [
         "Conv_1"
      ],
      "tensor0_lut": [
         1,
         1,
         1
      ],
      "tensor_mode": 0,
      "module_list": {
         "pre_cal": {
            "input_shape": [
               [
                  1,
                  3,
                  224,
                  224
               ]
            ],
            "output_shape": [
               [
                  1,
                  3,
                  224,
                  224
               ]
            ],
            "requan_scale_a": 1,
            "requan_zp_a": 0
         },
         "post_cal": {
            "mul_k": 53.59502410888672,
            "sum_b": -14.0,
            "sumsub_mode": "add",
            "carry_sel": "round",
            "input_shape": [
               [
                  1,
                  3,
                  224,
                  224
               ]
            ],
            "output_shape": [
               [
                  1,
                  3,
                  224,
                  224
               ]
            ]
         }
      },
      "ori_name": "src_quantize_1",
      "input_batchdim": [
         0
      ],
      "output_batchdim": [
         0
      ]
   },
   "Conv_1": {
      "layer_index": 1,
      "name": "Conv_1",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "int8"
      ],
      "input_shape": [
         [
            1,
            3,
            224,
            224
         ],
         [
            64,
            3,
            7,
            7
         ]
      ],
      "output_shape": [
         [
            1,
            64,
            112,
            112
         ]
      ],
      "quant_info": {
         "input_scale1": 0.01865844801068306,
         "input_zero_point1": 14.0,
         "output_scale": 47.47843584877144,
         "output_zero_point": -128.0,
         "round_type": "round"
      },
      "previous_layer": [
         "src_quantize_1_1",
         "constant_conv1_weight"
      ],
      "next_layer": [
         "MaxPool_4_1"
      ],
      "file_list": {
         "input_activation1": "Conv_1_input_activation1.npy",
         "input_activation2": "Conv_1_input_activation2.npy",
         "output_activation1": "Conv_1_output_activation1.npy",
         "k": "Conv_1_k.npy",
         "b": "Conv_1_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": "relu",
      "activation_attr": null,
      "kernel_size": [
         7,
         7
      ],
      "padding": [
         3,
         3,
         3,
         3
      ],
      "stride": [
         2,
         2
      ],
      "ori_name": "Relu_3"
   },
   "MaxPool_4_1": {
      "layer_index": 2,
      "name": "MaxPool_4_1",
      "operation": "max_pool2d",
      "device": "npu",
      "pool_size": [
         3,
         3
      ],
      "padding": [
         1,
         1,
         1,
         1
      ],
      "stride": [
         2,
         2
      ],
      "ceil_mode": 0,
      "file_list": {
         "input_activation1": "MaxPool_4_1_input_activation1.npy",
         "output_activation1": "MaxPool_4_1_output_activation1.npy"
      },
      "previous_layer": [
         "Conv_1"
      ],
      "next_layer": [
         "Conv_5",
         "dequantize_Add_10_input_2_1"
      ],
      "input_shape": [
         [
            1,
            64,
            112,
            112
         ]
      ],
      "output_shape": [
         [
            1,
            64,
            56,
            56
         ]
      ],
      "input_dtype": [
         "int8"
      ],
      "output_dtype": [
         "int8"
      ],
      "tensor0_lut": [
         1,
         1,
         1
      ],
      "module_list": {
         "pre_cal": {
            "requan_scale_a": 0.02106219343841076,
            "requan_zp_a": 2.695960760116577,
            "input_shape": [
               [
                  1,
                  64,
                  112,
                  112
               ]
            ],
            "output_shape": [
               [
                  1,
                  64,
                  112,
                  112
               ]
            ]
         },
         "compare_group": {
            "cmp_mode": "cumulative",
            "cmp_max_en": "max",
            "cmp_dim": "kernel",
            "input_shape": [
               [
                  1,
                  64,
                  112,
                  112
               ]
            ],
            "output_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ]
            ]
         },
         "post_cal": {
            "mul_k": 47.47843584877144,
            "sum_b": -128.0,
            "sumsub_mode": "add",
            "carry_sel": "round",
            "input_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ]
            ],
            "output_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ]
            ]
         }
      },
      "ori_name": "MaxPool_4",
      "input_batchdim": [
         0
      ],
      "output_batchdim": [
         0
      ]
   },
   "Conv_5": {
      "layer_index": 3,
      "name": "Conv_5",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "int8"
      ],
      "input_shape": [
         [
            1,
            64,
            56,
            56
         ],
         [
            64,
            64,
            3,
            3
         ]
      ],
      "output_shape": [
         [
            1,
            64,
            56,
            56
         ]
      ],
      "quant_info": {
         "input_scale1": 0.02106219343841076,
         "input_zero_point1": 128.0,
         "output_scale": 89.4273254508983,
         "output_zero_point": -128.0,
         "round_type": "round"
      },
      "previous_layer": [
         "MaxPool_4_1",
         "constant_layer1_0_conv1_weight"
      ],
      "next_layer": [
         "Conv_8"
      ],
      "file_list": {
         "input_activation1": "Conv_5_input_activation1.npy",
         "input_activation2": "Conv_5_input_activation2.npy",
         "output_activation1": "Conv_5_output_activation1.npy",
         "k": "Conv_5_k.npy",
         "b": "Conv_5_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": "relu",
      "activation_attr": null,
      "kernel_size": [
         3,
         3
      ],
      "padding": [
         1,
         1,
         1,
         1
      ],
      "stride": [
         1,
         1
      ],
      "ori_name": "Relu_7"
   },
   "dequantize_Add_10_input_2_1": {
      "layer_index": 4,
      "name": "dequantize_Add_10_input_2_1",
      "operation": "quantize",
      "device": "npu",
      "input_dtype": [
         "int8"
      ],
      "output_dtype": [
         "float16"
      ],
      "input_shape": [
         [
            1,
            64,
            56,
            56
         ]
      ],
      "output_shape": [
         [
            1,
            64,
            56,
            56
         ]
      ],
      "file_list": {
         "input_activation1": "dequantize_Add_10_input_2_1_input_activation1.npy",
         "output_activation1": "dequantize_Add_10_input_2_1_output_activation1.npy"
      },
      "previous_layer": [
         "MaxPool_4_1"
      ],
      "next_layer": [
         "Add_10_1"
      ],
      "tensor0_lut": [
         1,
         1,
         1
      ],
      "tensor_mode": 0,
      "module_list": {
         "pre_cal": {
            "requan_scale_a": 0.02106219343841076,
            "requan_zp_a": 2.695960760116577,
            "input_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ]
            ],
            "output_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ]
            ]
         },
         "post_cal": {
            "input_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ]
            ],
            "output_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ]
            ],
            "mul_k": 1,
            "sum_b": 0,
            "sumsub_mode": "add"
         }
      },
      "input_batchdim": [
         0
      ],
      "output_batchdim": [
         0
      ]
   },
   "Conv_8": {
      "layer_index": 5,
      "name": "Conv_8",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "float16"
      ],
      "input_shape": [
         [
            1,
            64,
            56,
            56
         ],
         [
            64,
            64,
            3,
            3
         ]
      ],
      "output_shape": [
         [
            1,
            64,
            56,
            56
         ]
      ],
      "quant_info": {
         "input_scale1": 0.011182264424860477,
         "input_zero_point1": 128.0
      },
      "previous_layer": [
         "Conv_5",
         "constant_layer1_0_conv2_weight"
      ],
      "next_layer": [
         "Add_10_1"
      ],
      "file_list": {
         "input_activation1": "Conv_8_input_activation1.npy",
         "input_activation2": "Conv_8_input_activation2.npy",
         "output_activation1": "Conv_8_output_activation1.npy",
         "k": "Conv_8_k.npy",
         "b": "Conv_8_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": null,
      "activation_attr": null,
      "kernel_size": [
         3,
         3
      ],
      "padding": [
         1,
         1,
         1,
         1
      ],
      "stride": [
         1,
         1
      ],
      "ori_name": "BatchNormalization_9"
   },
   "Add_10_1": {
      "layer_index": 6,
      "name": "Add_10_1",
      "operation": "element_wise_add",
      "device": "npu",
      "file_list": {
         "input_activation1": "Add_10_1_input_activation1.npy",
         "input_activation2": "Add_10_1_input_activation2.npy",
         "output_activation1": "Add_10_1_output_activation1.npy"
      },
      "previous_layer": [
         "Conv_8",
         "dequantize_Add_10_input_2_1"
      ],
      "next_layer": [
         "Conv_12",
         "dequantize_Add_17_input_2_1"
      ],
      "input_shape": [
         [
            1,
            64,
            56,
            56
         ],
         [
            1,
            64,
            56,
            56
         ]
      ],
      "output_shape": [
         [
            1,
            64,
            56,
            56
         ]
      ],
      "input_dtype": [
         "float16",
         "float16"
      ],
      "output_dtype": [
         "int8"
      ],
      "tensor0_lut": [
         1,
         1,
         1
      ],
      "tensor1_lut": [
         1,
         1,
         1
      ],
      "tensor_mode": 0,
      "module_list": {
         "pre_cal": {
            "input_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ],
               [
                  1,
                  64,
                  56,
                  56
               ]
            ],
            "output_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ],
               [
                  1,
                  64,
                  56,
                  56
               ]
            ],
            "requan_scale_a": 1,
            "requan_zp_a": 0,
            "requan_scale_b": 1,
            "requan_zp_b": 0
         },
         "fp32_sum_sub_group0": {
            "sumsub_group_mode": "add",
            "sumsub_group_b_mux": "vector",
            "input_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ],
               [
                  1,
                  64,
                  56,
                  56
               ]
            ],
            "output_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ]
            ]
         },
         "relu_group": {
            "input_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ]
            ],
            "output_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ]
            ]
         },
         "post_cal": {
            "mul_k": 45.08557881170347,
            "sum_b": -128.0,
            "sumsub_mode": "add",
            "carry_sel": "round",
            "input_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ]
            ],
            "output_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ]
            ]
         }
      },
      "ori_name": "Relu_11",
      "input_batchdim": [
         0,
         0
      ],
      "output_batchdim": [
         0
      ]
   },
   "Conv_12": {
      "layer_index": 7,
      "name": "Conv_12",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "int8"
      ],
      "input_shape": [
         [
            1,
            64,
            56,
            56
         ],
         [
            64,
            64,
            3,
            3
         ]
      ],
      "output_shape": [
         [
            1,
            64,
            56,
            56
         ]
      ],
      "quant_info": {
         "input_scale1": 0.022180041298270226,
         "input_zero_point1": 128.0,
         "output_scale": 99.65493134871483,
         "output_zero_point": -128.0,
         "round_type": "round"
      },
      "previous_layer": [
         "Add_10_1",
         "constant_layer1_1_conv1_weight"
      ],
      "next_layer": [
         "Conv_15"
      ],
      "file_list": {
         "input_activation1": "Conv_12_input_activation1.npy",
         "input_activation2": "Conv_12_input_activation2.npy",
         "output_activation1": "Conv_12_output_activation1.npy",
         "k": "Conv_12_k.npy",
         "b": "Conv_12_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": "relu",
      "activation_attr": null,
      "kernel_size": [
         3,
         3
      ],
      "padding": [
         1,
         1,
         1,
         1
      ],
      "stride": [
         1,
         1
      ],
      "ori_name": "Relu_14"
   },
   "dequantize_Add_17_input_2_1": {
      "layer_index": 8,
      "name": "dequantize_Add_17_input_2_1",
      "operation": "quantize",
      "device": "npu",
      "input_dtype": [
         "int8"
      ],
      "output_dtype": [
         "float16"
      ],
      "input_shape": [
         [
            1,
            64,
            56,
            56
         ]
      ],
      "output_shape": [
         [
            1,
            64,
            56,
            56
         ]
      ],
      "file_list": {
         "input_activation1": "dequantize_Add_17_input_2_1_input_activation1.npy",
         "output_activation1": "dequantize_Add_17_input_2_1_output_activation1.npy"
      },
      "previous_layer": [
         "Add_10_1"
      ],
      "next_layer": [
         "Add_17_1"
      ],
      "tensor0_lut": [
         1,
         1,
         1
      ],
      "tensor_mode": 0,
      "module_list": {
         "pre_cal": {
            "requan_scale_a": 0.022180041298270226,
            "requan_zp_a": 2.839045286178589,
            "input_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ]
            ],
            "output_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ]
            ]
         },
         "post_cal": {
            "input_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ]
            ],
            "output_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ]
            ],
            "mul_k": 1,
            "sum_b": 0,
            "sumsub_mode": "add"
         }
      },
      "input_batchdim": [
         0
      ],
      "output_batchdim": [
         0
      ]
   },
   "Conv_15": {
      "layer_index": 9,
      "name": "Conv_15",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "float16"
      ],
      "input_shape": [
         [
            1,
            64,
            56,
            56
         ],
         [
            64,
            64,
            3,
            3
         ]
      ],
      "output_shape": [
         [
            1,
            64,
            56,
            56
         ]
      ],
      "quant_info": {
         "input_scale1": 0.010034626349806786,
         "input_zero_point1": 128.0
      },
      "previous_layer": [
         "Conv_12",
         "constant_layer1_1_conv2_weight"
      ],
      "next_layer": [
         "Add_17_1"
      ],
      "file_list": {
         "input_activation1": "Conv_15_input_activation1.npy",
         "input_activation2": "Conv_15_input_activation2.npy",
         "output_activation1": "Conv_15_output_activation1.npy",
         "k": "Conv_15_k.npy",
         "b": "Conv_15_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": null,
      "activation_attr": null,
      "kernel_size": [
         3,
         3
      ],
      "padding": [
         1,
         1,
         1,
         1
      ],
      "stride": [
         1,
         1
      ],
      "ori_name": "BatchNormalization_16"
   },
   "Add_17_1": {
      "layer_index": 10,
      "name": "Add_17_1",
      "operation": "element_wise_add",
      "device": "npu",
      "file_list": {
         "input_activation1": "Add_17_1_input_activation1.npy",
         "input_activation2": "Add_17_1_input_activation2.npy",
         "output_activation1": "Add_17_1_output_activation1.npy"
      },
      "previous_layer": [
         "Conv_15",
         "dequantize_Add_17_input_2_1"
      ],
      "next_layer": [
         "Conv_19",
         "dequantize_Add_24_input_2_1"
      ],
      "input_shape": [
         [
            1,
            64,
            56,
            56
         ],
         [
            1,
            64,
            56,
            56
         ]
      ],
      "output_shape": [
         [
            1,
            64,
            56,
            56
         ]
      ],
      "input_dtype": [
         "float16",
         "float16"
      ],
      "output_dtype": [
         "int8"
      ],
      "tensor0_lut": [
         1,
         1,
         1
      ],
      "tensor1_lut": [
         1,
         1,
         1
      ],
      "tensor_mode": 0,
      "module_list": {
         "pre_cal": {
            "input_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ],
               [
                  1,
                  64,
                  56,
                  56
               ]
            ],
            "output_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ],
               [
                  1,
                  64,
                  56,
                  56
               ]
            ],
            "requan_scale_a": 1,
            "requan_zp_a": 0,
            "requan_scale_b": 1,
            "requan_zp_b": 0
         },
         "fp32_sum_sub_group0": {
            "sumsub_group_mode": "add",
            "sumsub_group_b_mux": "vector",
            "input_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ],
               [
                  1,
                  64,
                  56,
                  56
               ]
            ],
            "output_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ]
            ]
         },
         "relu_group": {
            "input_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ]
            ],
            "output_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ]
            ]
         },
         "post_cal": {
            "mul_k": 40.83949308513179,
            "sum_b": -128.0,
            "sumsub_mode": "add",
            "carry_sel": "round",
            "input_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ]
            ],
            "output_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ]
            ]
         }
      },
      "ori_name": "Relu_18",
      "input_batchdim": [
         0,
         0
      ],
      "output_batchdim": [
         0
      ]
   },
   "Conv_19": {
      "layer_index": 11,
      "name": "Conv_19",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "int8"
      ],
      "input_shape": [
         [
            1,
            64,
            56,
            56
         ],
         [
            64,
            64,
            3,
            3
         ]
      ],
      "output_shape": [
         [
            1,
            64,
            56,
            56
         ]
      ],
      "quant_info": {
         "input_scale1": 0.024486102163791656,
         "input_zero_point1": 128.0,
         "output_scale": 94.29886244187567,
         "output_zero_point": -128.0,
         "round_type": "round"
      },
      "previous_layer": [
         "Add_17_1",
         "constant_layer1_2_conv1_weight"
      ],
      "next_layer": [
         "Conv_22"
      ],
      "file_list": {
         "input_activation1": "Conv_19_input_activation1.npy",
         "input_activation2": "Conv_19_input_activation2.npy",
         "output_activation1": "Conv_19_output_activation1.npy",
         "k": "Conv_19_k.npy",
         "b": "Conv_19_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": "relu",
      "activation_attr": null,
      "kernel_size": [
         3,
         3
      ],
      "padding": [
         1,
         1,
         1,
         1
      ],
      "stride": [
         1,
         1
      ],
      "ori_name": "Relu_21"
   },
   "dequantize_Add_24_input_2_1": {
      "layer_index": 12,
      "name": "dequantize_Add_24_input_2_1",
      "operation": "quantize",
      "device": "npu",
      "input_dtype": [
         "int8"
      ],
      "output_dtype": [
         "float16"
      ],
      "input_shape": [
         [
            1,
            64,
            56,
            56
         ]
      ],
      "output_shape": [
         [
            1,
            64,
            56,
            56
         ]
      ],
      "file_list": {
         "input_activation1": "dequantize_Add_24_input_2_1_input_activation1.npy",
         "output_activation1": "dequantize_Add_24_input_2_1_output_activation1.npy"
      },
      "previous_layer": [
         "Add_17_1"
      ],
      "next_layer": [
         "Add_24_1"
      ],
      "tensor0_lut": [
         1,
         1,
         1
      ],
      "tensor_mode": 0,
      "module_list": {
         "pre_cal": {
            "requan_scale_a": 0.024486102163791656,
            "requan_zp_a": 3.134221076965332,
            "input_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ]
            ],
            "output_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ]
            ]
         },
         "post_cal": {
            "input_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ]
            ],
            "output_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ]
            ],
            "mul_k": 1,
            "sum_b": 0,
            "sumsub_mode": "add"
         }
      },
      "input_batchdim": [
         0
      ],
      "output_batchdim": [
         0
      ]
   },
   "Conv_22": {
      "layer_index": 13,
      "name": "Conv_22",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "float16"
      ],
      "input_shape": [
         [
            1,
            64,
            56,
            56
         ],
         [
            64,
            64,
            3,
            3
         ]
      ],
      "output_shape": [
         [
            1,
            64,
            56,
            56
         ]
      ],
      "quant_info": {
         "input_scale1": 0.01060458179563284,
         "input_zero_point1": 128.0
      },
      "previous_layer": [
         "Conv_19",
         "constant_layer1_2_conv2_weight"
      ],
      "next_layer": [
         "Add_24_1"
      ],
      "file_list": {
         "input_activation1": "Conv_22_input_activation1.npy",
         "input_activation2": "Conv_22_input_activation2.npy",
         "output_activation1": "Conv_22_output_activation1.npy",
         "k": "Conv_22_k.npy",
         "b": "Conv_22_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": null,
      "activation_attr": null,
      "kernel_size": [
         3,
         3
      ],
      "padding": [
         1,
         1,
         1,
         1
      ],
      "stride": [
         1,
         1
      ],
      "ori_name": "BatchNormalization_23"
   },
   "Add_24_1": {
      "layer_index": 14,
      "name": "Add_24_1",
      "operation": "element_wise_add",
      "device": "npu",
      "file_list": {
         "input_activation1": "Add_24_1_input_activation1.npy",
         "input_activation2": "Add_24_1_input_activation2.npy",
         "output_activation1": "Add_24_1_output_activation1.npy"
      },
      "previous_layer": [
         "Conv_22",
         "dequantize_Add_24_input_2_1"
      ],
      "next_layer": [
         "Conv_26",
         "Conv_31"
      ],
      "input_shape": [
         [
            1,
            64,
            56,
            56
         ],
         [
            1,
            64,
            56,
            56
         ]
      ],
      "output_shape": [
         [
            1,
            64,
            56,
            56
         ]
      ],
      "input_dtype": [
         "float16",
         "float16"
      ],
      "output_dtype": [
         "int8"
      ],
      "tensor0_lut": [
         1,
         1,
         1
      ],
      "tensor1_lut": [
         1,
         1,
         1
      ],
      "tensor_mode": 0,
      "module_list": {
         "pre_cal": {
            "input_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ],
               [
                  1,
                  64,
                  56,
                  56
               ]
            ],
            "output_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ],
               [
                  1,
                  64,
                  56,
                  56
               ]
            ],
            "requan_scale_a": 1,
            "requan_zp_a": 0,
            "requan_scale_b": 1,
            "requan_zp_b": 0
         },
         "fp32_sum_sub_group0": {
            "sumsub_group_mode": "add",
            "sumsub_group_b_mux": "vector",
            "input_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ],
               [
                  1,
                  64,
                  56,
                  56
               ]
            ],
            "output_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ]
            ]
         },
         "relu_group": {
            "input_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ]
            ],
            "output_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ]
            ]
         },
         "post_cal": {
            "mul_k": 35.62118187784822,
            "sum_b": -128.0,
            "sumsub_mode": "add",
            "carry_sel": "round",
            "input_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ]
            ],
            "output_shape": [
               [
                  1,
                  64,
                  56,
                  56
               ]
            ]
         }
      },
      "ori_name": "Relu_25",
      "input_batchdim": [
         0,
         0
      ],
      "output_batchdim": [
         0
      ]
   },
   "Conv_26": {
      "layer_index": 15,
      "name": "Conv_26",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "int8"
      ],
      "input_shape": [
         [
            1,
            64,
            56,
            56
         ],
         [
            128,
            64,
            3,
            3
         ]
      ],
      "output_shape": [
         [
            1,
            128,
            28,
            28
         ]
      ],
      "quant_info": {
         "input_scale1": 0.028073184192180634,
         "input_zero_point1": 128.0,
         "output_scale": 117.16795918868414,
         "output_zero_point": -128.0,
         "round_type": "round"
      },
      "previous_layer": [
         "Add_24_1",
         "constant_layer2_0_conv1_weight"
      ],
      "next_layer": [
         "Conv_29"
      ],
      "file_list": {
         "input_activation1": "Conv_26_input_activation1.npy",
         "input_activation2": "Conv_26_input_activation2.npy",
         "output_activation1": "Conv_26_output_activation1.npy",
         "k": "Conv_26_k.npy",
         "b": "Conv_26_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": "relu",
      "activation_attr": null,
      "kernel_size": [
         3,
         3
      ],
      "padding": [
         1,
         1,
         1,
         1
      ],
      "stride": [
         2,
         2
      ],
      "ori_name": "Relu_28"
   },
   "Conv_31": {
      "layer_index": 16,
      "name": "Conv_31",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "float16"
      ],
      "input_shape": [
         [
            1,
            64,
            56,
            56
         ],
         [
            128,
            64,
            1,
            1
         ]
      ],
      "output_shape": [
         [
            1,
            128,
            28,
            28
         ]
      ],
      "quant_info": {
         "input_scale1": 0.028073184192180634,
         "input_zero_point1": 128.0
      },
      "previous_layer": [
         "Add_24_1",
         "constant_layer2_0_downsample_0_weight"
      ],
      "next_layer": [
         "Add_33_1"
      ],
      "file_list": {
         "input_activation1": "Conv_31_input_activation1.npy",
         "input_activation2": "Conv_31_input_activation2.npy",
         "output_activation1": "Conv_31_output_activation1.npy",
         "k": "Conv_31_k.npy",
         "b": "Conv_31_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": null,
      "activation_attr": null,
      "kernel_size": [
         1,
         1
      ],
      "padding": [
         0,
         0,
         0,
         0
      ],
      "stride": [
         2,
         2
      ],
      "ori_name": "BatchNormalization_32"
   },
   "Conv_29": {
      "layer_index": 17,
      "name": "Conv_29",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "float16"
      ],
      "input_shape": [
         [
            1,
            128,
            28,
            28
         ],
         [
            128,
            128,
            3,
            3
         ]
      ],
      "output_shape": [
         [
            1,
            128,
            28,
            28
         ]
      ],
      "quant_info": {
         "input_scale1": 0.008534756489098072,
         "input_zero_point1": 128.0
      },
      "previous_layer": [
         "Conv_26",
         "constant_layer2_0_conv2_weight"
      ],
      "next_layer": [
         "Add_33_1"
      ],
      "file_list": {
         "input_activation1": "Conv_29_input_activation1.npy",
         "input_activation2": "Conv_29_input_activation2.npy",
         "output_activation1": "Conv_29_output_activation1.npy",
         "k": "Conv_29_k.npy",
         "b": "Conv_29_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": null,
      "activation_attr": null,
      "kernel_size": [
         3,
         3
      ],
      "padding": [
         1,
         1,
         1,
         1
      ],
      "stride": [
         1,
         1
      ],
      "ori_name": "BatchNormalization_30"
   },
   "Add_33_1": {
      "layer_index": 18,
      "name": "Add_33_1",
      "operation": "element_wise_add",
      "device": "npu",
      "file_list": {
         "input_activation1": "Add_33_1_input_activation1.npy",
         "input_activation2": "Add_33_1_input_activation2.npy",
         "output_activation1": "Add_33_1_output_activation1.npy"
      },
      "previous_layer": [
         "Conv_29",
         "Conv_31"
      ],
      "next_layer": [
         "Conv_35",
         "dequantize_Add_40_input_2_1"
      ],
      "input_shape": [
         [
            1,
            128,
            28,
            28
         ],
         [
            1,
            128,
            28,
            28
         ]
      ],
      "output_shape": [
         [
            1,
            128,
            28,
            28
         ]
      ],
      "input_dtype": [
         "float16",
         "float16"
      ],
      "output_dtype": [
         "int8"
      ],
      "tensor0_lut": [
         1,
         1,
         1
      ],
      "tensor1_lut": [
         1,
         1,
         1
      ],
      "tensor_mode": 0,
      "module_list": {
         "pre_cal": {
            "input_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ],
               [
                  1,
                  128,
                  28,
                  28
               ]
            ],
            "output_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ],
               [
                  1,
                  128,
                  28,
                  28
               ]
            ],
            "requan_scale_a": 1,
            "requan_zp_a": 0,
            "requan_scale_b": 1,
            "requan_zp_b": 0
         },
         "fp32_sum_sub_group0": {
            "sumsub_group_mode": "add",
            "sumsub_group_b_mux": "vector",
            "input_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ],
               [
                  1,
                  128,
                  28,
                  28
               ]
            ],
            "output_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ]
            ]
         },
         "relu_group": {
            "input_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ]
            ],
            "output_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ]
            ]
         },
         "post_cal": {
            "mul_k": 49.82902881497198,
            "sum_b": -128.0,
            "sumsub_mode": "add",
            "carry_sel": "round",
            "input_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ]
            ],
            "output_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ]
            ]
         }
      },
      "ori_name": "Relu_34",
      "input_batchdim": [
         0,
         0
      ],
      "output_batchdim": [
         0
      ]
   },
   "Conv_35": {
      "layer_index": 19,
      "name": "Conv_35",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "int8"
      ],
      "input_shape": [
         [
            1,
            128,
            28,
            28
         ],
         [
            128,
            128,
            3,
            3
         ]
      ],
      "output_shape": [
         [
            1,
            128,
            28,
            28
         ]
      ],
      "quant_info": {
         "input_scale1": 0.02006862312555313,
         "input_zero_point1": 128.0,
         "output_scale": 138.02455743912395,
         "output_zero_point": -128.0,
         "round_type": "round"
      },
      "previous_layer": [
         "Add_33_1",
         "constant_layer2_1_conv1_weight"
      ],
      "next_layer": [
         "Conv_38"
      ],
      "file_list": {
         "input_activation1": "Conv_35_input_activation1.npy",
         "input_activation2": "Conv_35_input_activation2.npy",
         "output_activation1": "Conv_35_output_activation1.npy",
         "k": "Conv_35_k.npy",
         "b": "Conv_35_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": "relu",
      "activation_attr": null,
      "kernel_size": [
         3,
         3
      ],
      "padding": [
         1,
         1,
         1,
         1
      ],
      "stride": [
         1,
         1
      ],
      "ori_name": "Relu_37"
   },
   "dequantize_Add_40_input_2_1": {
      "layer_index": 20,
      "name": "dequantize_Add_40_input_2_1",
      "operation": "quantize",
      "device": "npu",
      "input_dtype": [
         "int8"
      ],
      "output_dtype": [
         "float16"
      ],
      "input_shape": [
         [
            1,
            128,
            28,
            28
         ]
      ],
      "output_shape": [
         [
            1,
            128,
            28,
            28
         ]
      ],
      "file_list": {
         "input_activation1": "dequantize_Add_40_input_2_1_input_activation1.npy",
         "output_activation1": "dequantize_Add_40_input_2_1_output_activation1.npy"
      },
      "previous_layer": [
         "Add_33_1"
      ],
      "next_layer": [
         "Add_40_1"
      ],
      "tensor0_lut": [
         1,
         1,
         1
      ],
      "tensor_mode": 0,
      "module_list": {
         "pre_cal": {
            "requan_scale_a": 0.02006862312555313,
            "requan_zp_a": 2.568783760070801,
            "input_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ]
            ],
            "output_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ]
            ]
         },
         "post_cal": {
            "input_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ]
            ],
            "output_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ]
            ],
            "mul_k": 1,
            "sum_b": 0,
            "sumsub_mode": "add"
         }
      },
      "input_batchdim": [
         0
      ],
      "output_batchdim": [
         0
      ]
   },
   "Conv_38": {
      "layer_index": 21,
      "name": "Conv_38",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "float16"
      ],
      "input_shape": [
         [
            1,
            128,
            28,
            28
         ],
         [
            128,
            128,
            3,
            3
         ]
      ],
      "output_shape": [
         [
            1,
            128,
            28,
            28
         ]
      ],
      "quant_info": {
         "input_scale1": 0.007245087530463934,
         "input_zero_point1": 128.0
      },
      "previous_layer": [
         "Conv_35",
         "constant_layer2_1_conv2_weight"
      ],
      "next_layer": [
         "Add_40_1"
      ],
      "file_list": {
         "input_activation1": "Conv_38_input_activation1.npy",
         "input_activation2": "Conv_38_input_activation2.npy",
         "output_activation1": "Conv_38_output_activation1.npy",
         "k": "Conv_38_k.npy",
         "b": "Conv_38_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": null,
      "activation_attr": null,
      "kernel_size": [
         3,
         3
      ],
      "padding": [
         1,
         1,
         1,
         1
      ],
      "stride": [
         1,
         1
      ],
      "ori_name": "BatchNormalization_39"
   },
   "Add_40_1": {
      "layer_index": 22,
      "name": "Add_40_1",
      "operation": "element_wise_add",
      "device": "npu",
      "file_list": {
         "input_activation1": "Add_40_1_input_activation1.npy",
         "input_activation2": "Add_40_1_input_activation2.npy",
         "output_activation1": "Add_40_1_output_activation1.npy"
      },
      "previous_layer": [
         "Conv_38",
         "dequantize_Add_40_input_2_1"
      ],
      "next_layer": [
         "Conv_42",
         "dequantize_Add_47_input_2_1"
      ],
      "input_shape": [
         [
            1,
            128,
            28,
            28
         ],
         [
            1,
            128,
            28,
            28
         ]
      ],
      "output_shape": [
         [
            1,
            128,
            28,
            28
         ]
      ],
      "input_dtype": [
         "float16",
         "float16"
      ],
      "output_dtype": [
         "int8"
      ],
      "tensor0_lut": [
         1,
         1,
         1
      ],
      "tensor1_lut": [
         1,
         1,
         1
      ],
      "tensor_mode": 0,
      "module_list": {
         "pre_cal": {
            "input_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ],
               [
                  1,
                  128,
                  28,
                  28
               ]
            ],
            "output_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ],
               [
                  1,
                  128,
                  28,
                  28
               ]
            ],
            "requan_scale_a": 1,
            "requan_zp_a": 0,
            "requan_scale_b": 1,
            "requan_zp_b": 0
         },
         "fp32_sum_sub_group0": {
            "sumsub_group_mode": "add",
            "sumsub_group_b_mux": "vector",
            "input_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ],
               [
                  1,
                  128,
                  28,
                  28
               ]
            ],
            "output_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ]
            ]
         },
         "relu_group": {
            "input_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ]
            ],
            "output_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ]
            ]
         },
         "post_cal": {
            "mul_k": 50.79213745443337,
            "sum_b": -128.0,
            "sumsub_mode": "add",
            "carry_sel": "round",
            "input_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ]
            ],
            "output_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ]
            ]
         }
      },
      "ori_name": "Relu_41",
      "input_batchdim": [
         0,
         0
      ],
      "output_batchdim": [
         0
      ]
   },
   "Conv_42": {
      "layer_index": 23,
      "name": "Conv_42",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "int8"
      ],
      "input_shape": [
         [
            1,
            128,
            28,
            28
         ],
         [
            128,
            128,
            3,
            3
         ]
      ],
      "output_shape": [
         [
            1,
            128,
            28,
            28
         ]
      ],
      "quant_info": {
         "input_scale1": 0.019688086584210396,
         "input_zero_point1": 128.0,
         "output_scale": 83.11613240874205,
         "output_zero_point": -128.0,
         "round_type": "round"
      },
      "previous_layer": [
         "Add_40_1",
         "constant_layer2_2_conv1_weight"
      ],
      "next_layer": [
         "Conv_45"
      ],
      "file_list": {
         "input_activation1": "Conv_42_input_activation1.npy",
         "input_activation2": "Conv_42_input_activation2.npy",
         "output_activation1": "Conv_42_output_activation1.npy",
         "k": "Conv_42_k.npy",
         "b": "Conv_42_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": "relu",
      "activation_attr": null,
      "kernel_size": [
         3,
         3
      ],
      "padding": [
         1,
         1,
         1,
         1
      ],
      "stride": [
         1,
         1
      ],
      "ori_name": "Relu_44"
   },
   "dequantize_Add_47_input_2_1": {
      "layer_index": 24,
      "name": "dequantize_Add_47_input_2_1",
      "operation": "quantize",
      "device": "npu",
      "input_dtype": [
         "int8"
      ],
      "output_dtype": [
         "float16"
      ],
      "input_shape": [
         [
            1,
            128,
            28,
            28
         ]
      ],
      "output_shape": [
         [
            1,
            128,
            28,
            28
         ]
      ],
      "file_list": {
         "input_activation1": "dequantize_Add_47_input_2_1_input_activation1.npy",
         "output_activation1": "dequantize_Add_47_input_2_1_output_activation1.npy"
      },
      "previous_layer": [
         "Add_40_1"
      ],
      "next_layer": [
         "Add_47_1"
      ],
      "tensor0_lut": [
         1,
         1,
         1
      ],
      "tensor_mode": 0,
      "module_list": {
         "pre_cal": {
            "requan_scale_a": 0.019688086584210396,
            "requan_zp_a": 2.5200750827789307,
            "input_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ]
            ],
            "output_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ]
            ]
         },
         "post_cal": {
            "input_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ]
            ],
            "output_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ]
            ],
            "mul_k": 1,
            "sum_b": 0,
            "sumsub_mode": "add"
         }
      },
      "input_batchdim": [
         0
      ],
      "output_batchdim": [
         0
      ]
   },
   "Conv_45": {
      "layer_index": 25,
      "name": "Conv_45",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "float16"
      ],
      "input_shape": [
         [
            1,
            128,
            28,
            28
         ],
         [
            128,
            128,
            3,
            3
         ]
      ],
      "output_shape": [
         [
            1,
            128,
            28,
            28
         ]
      ],
      "quant_info": {
         "input_scale1": 0.012031358666718006,
         "input_zero_point1": 128.0
      },
      "previous_layer": [
         "Conv_42",
         "constant_layer2_2_conv2_weight"
      ],
      "next_layer": [
         "Add_47_1"
      ],
      "file_list": {
         "input_activation1": "Conv_45_input_activation1.npy",
         "input_activation2": "Conv_45_input_activation2.npy",
         "output_activation1": "Conv_45_output_activation1.npy",
         "k": "Conv_45_k.npy",
         "b": "Conv_45_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": null,
      "activation_attr": null,
      "kernel_size": [
         3,
         3
      ],
      "padding": [
         1,
         1,
         1,
         1
      ],
      "stride": [
         1,
         1
      ],
      "ori_name": "BatchNormalization_46"
   },
   "Add_47_1": {
      "layer_index": 26,
      "name": "Add_47_1",
      "operation": "element_wise_add",
      "device": "npu",
      "file_list": {
         "input_activation1": "Add_47_1_input_activation1.npy",
         "input_activation2": "Add_47_1_input_activation2.npy",
         "output_activation1": "Add_47_1_output_activation1.npy"
      },
      "previous_layer": [
         "Conv_45",
         "dequantize_Add_47_input_2_1"
      ],
      "next_layer": [
         "Conv_49",
         "dequantize_Add_54_input_2_1"
      ],
      "input_shape": [
         [
            1,
            128,
            28,
            28
         ],
         [
            1,
            128,
            28,
            28
         ]
      ],
      "output_shape": [
         [
            1,
            128,
            28,
            28
         ]
      ],
      "input_dtype": [
         "float16",
         "float16"
      ],
      "output_dtype": [
         "int8"
      ],
      "tensor0_lut": [
         1,
         1,
         1
      ],
      "tensor1_lut": [
         1,
         1,
         1
      ],
      "tensor_mode": 0,
      "module_list": {
         "pre_cal": {
            "input_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ],
               [
                  1,
                  128,
                  28,
                  28
               ]
            ],
            "output_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ],
               [
                  1,
                  128,
                  28,
                  28
               ]
            ],
            "requan_scale_a": 1,
            "requan_zp_a": 0,
            "requan_scale_b": 1,
            "requan_zp_b": 0
         },
         "fp32_sum_sub_group0": {
            "sumsub_group_mode": "add",
            "sumsub_group_b_mux": "vector",
            "input_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ],
               [
                  1,
                  128,
                  28,
                  28
               ]
            ],
            "output_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ]
            ]
         },
         "relu_group": {
            "input_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ]
            ],
            "output_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ]
            ]
         },
         "post_cal": {
            "mul_k": 42.15642727182569,
            "sum_b": -128.0,
            "sumsub_mode": "add",
            "carry_sel": "round",
            "input_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ]
            ],
            "output_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ]
            ]
         }
      },
      "ori_name": "Relu_48",
      "input_batchdim": [
         0,
         0
      ],
      "output_batchdim": [
         0
      ]
   },
   "Conv_49": {
      "layer_index": 27,
      "name": "Conv_49",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "int8"
      ],
      "input_shape": [
         [
            1,
            128,
            28,
            28
         ],
         [
            128,
            128,
            3,
            3
         ]
      ],
      "output_shape": [
         [
            1,
            128,
            28,
            28
         ]
      ],
      "quant_info": {
         "input_scale1": 0.023721175268292427,
         "input_zero_point1": 128.0,
         "output_scale": 119.00537503852811,
         "output_zero_point": -128.0,
         "round_type": "round"
      },
      "previous_layer": [
         "Add_47_1",
         "constant_layer2_3_conv1_weight"
      ],
      "next_layer": [
         "Conv_52"
      ],
      "file_list": {
         "input_activation1": "Conv_49_input_activation1.npy",
         "input_activation2": "Conv_49_input_activation2.npy",
         "output_activation1": "Conv_49_output_activation1.npy",
         "k": "Conv_49_k.npy",
         "b": "Conv_49_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": "relu",
      "activation_attr": null,
      "kernel_size": [
         3,
         3
      ],
      "padding": [
         1,
         1,
         1,
         1
      ],
      "stride": [
         1,
         1
      ],
      "ori_name": "Relu_51"
   },
   "dequantize_Add_54_input_2_1": {
      "layer_index": 28,
      "name": "dequantize_Add_54_input_2_1",
      "operation": "quantize",
      "device": "npu",
      "input_dtype": [
         "int8"
      ],
      "output_dtype": [
         "float16"
      ],
      "input_shape": [
         [
            1,
            128,
            28,
            28
         ]
      ],
      "output_shape": [
         [
            1,
            128,
            28,
            28
         ]
      ],
      "file_list": {
         "input_activation1": "dequantize_Add_54_input_2_1_input_activation1.npy",
         "output_activation1": "dequantize_Add_54_input_2_1_output_activation1.npy"
      },
      "previous_layer": [
         "Add_47_1"
      ],
      "next_layer": [
         "Add_54_1"
      ],
      "tensor0_lut": [
         1,
         1,
         1
      ],
      "tensor_mode": 0,
      "module_list": {
         "pre_cal": {
            "requan_scale_a": 0.023721175268292427,
            "requan_zp_a": 3.0363104343414307,
            "input_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ]
            ],
            "output_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ]
            ]
         },
         "post_cal": {
            "input_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ]
            ],
            "output_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ]
            ],
            "mul_k": 1,
            "sum_b": 0,
            "sumsub_mode": "add"
         }
      },
      "input_batchdim": [
         0
      ],
      "output_batchdim": [
         0
      ]
   },
   "Conv_52": {
      "layer_index": 29,
      "name": "Conv_52",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "float16"
      ],
      "input_shape": [
         [
            1,
            128,
            28,
            28
         ],
         [
            128,
            128,
            3,
            3
         ]
      ],
      "output_shape": [
         [
            1,
            128,
            28,
            28
         ]
      ],
      "quant_info": {
         "input_scale1": 0.008402981795370579,
         "input_zero_point1": 128.0
      },
      "previous_layer": [
         "Conv_49",
         "constant_layer2_3_conv2_weight"
      ],
      "next_layer": [
         "Add_54_1"
      ],
      "file_list": {
         "input_activation1": "Conv_52_input_activation1.npy",
         "input_activation2": "Conv_52_input_activation2.npy",
         "output_activation1": "Conv_52_output_activation1.npy",
         "k": "Conv_52_k.npy",
         "b": "Conv_52_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": null,
      "activation_attr": null,
      "kernel_size": [
         3,
         3
      ],
      "padding": [
         1,
         1,
         1,
         1
      ],
      "stride": [
         1,
         1
      ],
      "ori_name": "BatchNormalization_53"
   },
   "Add_54_1": {
      "layer_index": 30,
      "name": "Add_54_1",
      "operation": "element_wise_add",
      "device": "npu",
      "file_list": {
         "input_activation1": "Add_54_1_input_activation1.npy",
         "input_activation2": "Add_54_1_input_activation2.npy",
         "output_activation1": "Add_54_1_output_activation1.npy"
      },
      "previous_layer": [
         "Conv_52",
         "dequantize_Add_54_input_2_1"
      ],
      "next_layer": [
         "Conv_56",
         "Conv_61"
      ],
      "input_shape": [
         [
            1,
            128,
            28,
            28
         ],
         [
            1,
            128,
            28,
            28
         ]
      ],
      "output_shape": [
         [
            1,
            128,
            28,
            28
         ]
      ],
      "input_dtype": [
         "float16",
         "float16"
      ],
      "output_dtype": [
         "int8"
      ],
      "tensor0_lut": [
         1,
         1,
         1
      ],
      "tensor1_lut": [
         1,
         1,
         1
      ],
      "tensor_mode": 0,
      "module_list": {
         "pre_cal": {
            "input_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ],
               [
                  1,
                  128,
                  28,
                  28
               ]
            ],
            "output_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ],
               [
                  1,
                  128,
                  28,
                  28
               ]
            ],
            "requan_scale_a": 1,
            "requan_zp_a": 0,
            "requan_scale_b": 1,
            "requan_zp_b": 0
         },
         "fp32_sum_sub_group0": {
            "sumsub_group_mode": "add",
            "sumsub_group_b_mux": "vector",
            "input_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ],
               [
                  1,
                  128,
                  28,
                  28
               ]
            ],
            "output_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ]
            ]
         },
         "relu_group": {
            "input_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ]
            ],
            "output_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ]
            ]
         },
         "post_cal": {
            "mul_k": 40.52353843928899,
            "sum_b": -128.0,
            "sumsub_mode": "add",
            "carry_sel": "round",
            "input_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ]
            ],
            "output_shape": [
               [
                  1,
                  128,
                  28,
                  28
               ]
            ]
         }
      },
      "ori_name": "Relu_55",
      "input_batchdim": [
         0,
         0
      ],
      "output_batchdim": [
         0
      ]
   },
   "Conv_56": {
      "layer_index": 31,
      "name": "Conv_56",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "int8"
      ],
      "input_shape": [
         [
            1,
            128,
            28,
            28
         ],
         [
            256,
            128,
            3,
            3
         ]
      ],
      "output_shape": [
         [
            1,
            256,
            14,
            14
         ]
      ],
      "quant_info": {
         "input_scale1": 0.024677015841007233,
         "input_zero_point1": 128.0,
         "output_scale": 94.14551381702795,
         "output_zero_point": -128.0,
         "round_type": "round"
      },
      "previous_layer": [
         "Add_54_1",
         "constant_layer3_0_conv1_weight"
      ],
      "next_layer": [
         "Conv_59"
      ],
      "file_list": {
         "input_activation1": "Conv_56_input_activation1.npy",
         "input_activation2": "Conv_56_input_activation2.npy",
         "output_activation1": "Conv_56_output_activation1.npy",
         "k": "Conv_56_k.npy",
         "b": "Conv_56_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": "relu",
      "activation_attr": null,
      "kernel_size": [
         3,
         3
      ],
      "padding": [
         1,
         1,
         1,
         1
      ],
      "stride": [
         2,
         2
      ],
      "ori_name": "Relu_58"
   },
   "Conv_61": {
      "layer_index": 32,
      "name": "Conv_61",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "float16"
      ],
      "input_shape": [
         [
            1,
            128,
            28,
            28
         ],
         [
            256,
            128,
            1,
            1
         ]
      ],
      "output_shape": [
         [
            1,
            256,
            14,
            14
         ]
      ],
      "quant_info": {
         "input_scale1": 0.024677015841007233,
         "input_zero_point1": 128.0
      },
      "previous_layer": [
         "Add_54_1",
         "constant_layer3_0_downsample_0_weight"
      ],
      "next_layer": [
         "Add_63_1"
      ],
      "file_list": {
         "input_activation1": "Conv_61_input_activation1.npy",
         "input_activation2": "Conv_61_input_activation2.npy",
         "output_activation1": "Conv_61_output_activation1.npy",
         "k": "Conv_61_k.npy",
         "b": "Conv_61_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": null,
      "activation_attr": null,
      "kernel_size": [
         1,
         1
      ],
      "padding": [
         0,
         0,
         0,
         0
      ],
      "stride": [
         2,
         2
      ],
      "ori_name": "BatchNormalization_62"
   },
   "Conv_59": {
      "layer_index": 33,
      "name": "Conv_59",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "float16"
      ],
      "input_shape": [
         [
            1,
            256,
            14,
            14
         ],
         [
            256,
            256,
            3,
            3
         ]
      ],
      "output_shape": [
         [
            1,
            256,
            14,
            14
         ]
      ],
      "quant_info": {
         "input_scale1": 0.010621855035424232,
         "input_zero_point1": 128.0
      },
      "previous_layer": [
         "Conv_56",
         "constant_layer3_0_conv2_weight"
      ],
      "next_layer": [
         "Add_63_1"
      ],
      "file_list": {
         "input_activation1": "Conv_59_input_activation1.npy",
         "input_activation2": "Conv_59_input_activation2.npy",
         "output_activation1": "Conv_59_output_activation1.npy",
         "k": "Conv_59_k.npy",
         "b": "Conv_59_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": null,
      "activation_attr": null,
      "kernel_size": [
         3,
         3
      ],
      "padding": [
         1,
         1,
         1,
         1
      ],
      "stride": [
         1,
         1
      ],
      "ori_name": "BatchNormalization_60"
   },
   "Add_63_1": {
      "layer_index": 34,
      "name": "Add_63_1",
      "operation": "element_wise_add",
      "device": "npu",
      "file_list": {
         "input_activation1": "Add_63_1_input_activation1.npy",
         "input_activation2": "Add_63_1_input_activation2.npy",
         "output_activation1": "Add_63_1_output_activation1.npy"
      },
      "previous_layer": [
         "Conv_59",
         "Conv_61"
      ],
      "next_layer": [
         "Conv_65",
         "dequantize_Add_70_input_2_1"
      ],
      "input_shape": [
         [
            1,
            256,
            14,
            14
         ],
         [
            1,
            256,
            14,
            14
         ]
      ],
      "output_shape": [
         [
            1,
            256,
            14,
            14
         ]
      ],
      "input_dtype": [
         "float16",
         "float16"
      ],
      "output_dtype": [
         "int8"
      ],
      "tensor0_lut": [
         1,
         1,
         1
      ],
      "tensor1_lut": [
         1,
         1,
         1
      ],
      "tensor_mode": 0,
      "module_list": {
         "pre_cal": {
            "input_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ],
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "output_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ],
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "requan_scale_a": 1,
            "requan_zp_a": 0,
            "requan_scale_b": 1,
            "requan_zp_b": 0
         },
         "fp32_sum_sub_group0": {
            "sumsub_group_mode": "add",
            "sumsub_group_b_mux": "vector",
            "input_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ],
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "output_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ]
         },
         "relu_group": {
            "input_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "output_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ]
         },
         "post_cal": {
            "mul_k": 48.26655875852656,
            "sum_b": -128.0,
            "sumsub_mode": "add",
            "carry_sel": "round",
            "input_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "output_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ]
         }
      },
      "ori_name": "Relu_64",
      "input_batchdim": [
         0,
         0
      ],
      "output_batchdim": [
         0
      ]
   },
   "Conv_65": {
      "layer_index": 35,
      "name": "Conv_65",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "int8"
      ],
      "input_shape": [
         [
            1,
            256,
            14,
            14
         ],
         [
            256,
            256,
            3,
            3
         ]
      ],
      "output_shape": [
         [
            1,
            256,
            14,
            14
         ]
      ],
      "quant_info": {
         "input_scale1": 0.020718278363347054,
         "input_zero_point1": 128.0,
         "output_scale": 145.68903691656016,
         "output_zero_point": -128.0,
         "round_type": "round"
      },
      "previous_layer": [
         "Add_63_1",
         "constant_layer3_1_conv1_weight"
      ],
      "next_layer": [
         "Conv_68"
      ],
      "file_list": {
         "input_activation1": "Conv_65_input_activation1.npy",
         "input_activation2": "Conv_65_input_activation2.npy",
         "output_activation1": "Conv_65_output_activation1.npy",
         "k": "Conv_65_k.npy",
         "b": "Conv_65_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": "relu",
      "activation_attr": null,
      "kernel_size": [
         3,
         3
      ],
      "padding": [
         1,
         1,
         1,
         1
      ],
      "stride": [
         1,
         1
      ],
      "ori_name": "Relu_67"
   },
   "dequantize_Add_70_input_2_1": {
      "layer_index": 36,
      "name": "dequantize_Add_70_input_2_1",
      "operation": "quantize",
      "device": "npu",
      "input_dtype": [
         "int8"
      ],
      "output_dtype": [
         "float16"
      ],
      "input_shape": [
         [
            1,
            256,
            14,
            14
         ]
      ],
      "output_shape": [
         [
            1,
            256,
            14,
            14
         ]
      ],
      "file_list": {
         "input_activation1": "dequantize_Add_70_input_2_1_input_activation1.npy",
         "output_activation1": "dequantize_Add_70_input_2_1_output_activation1.npy"
      },
      "previous_layer": [
         "Add_63_1"
      ],
      "next_layer": [
         "Add_70_1"
      ],
      "tensor0_lut": [
         1,
         1,
         1
      ],
      "tensor_mode": 0,
      "module_list": {
         "pre_cal": {
            "requan_scale_a": 0.020718278363347054,
            "requan_zp_a": 2.651939630508423,
            "input_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "output_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ]
         },
         "post_cal": {
            "input_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "output_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "mul_k": 1,
            "sum_b": 0,
            "sumsub_mode": "add"
         }
      },
      "input_batchdim": [
         0
      ],
      "output_batchdim": [
         0
      ]
   },
   "Conv_68": {
      "layer_index": 37,
      "name": "Conv_68",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "float16"
      ],
      "input_shape": [
         [
            1,
            256,
            14,
            14
         ],
         [
            256,
            256,
            3,
            3
         ]
      ],
      "output_shape": [
         [
            1,
            256,
            14,
            14
         ]
      ],
      "quant_info": {
         "input_scale1": 0.006863934453576803,
         "input_zero_point1": 128.0
      },
      "previous_layer": [
         "Conv_65",
         "constant_layer3_1_conv2_weight"
      ],
      "next_layer": [
         "Add_70_1"
      ],
      "file_list": {
         "input_activation1": "Conv_68_input_activation1.npy",
         "input_activation2": "Conv_68_input_activation2.npy",
         "output_activation1": "Conv_68_output_activation1.npy",
         "k": "Conv_68_k.npy",
         "b": "Conv_68_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": null,
      "activation_attr": null,
      "kernel_size": [
         3,
         3
      ],
      "padding": [
         1,
         1,
         1,
         1
      ],
      "stride": [
         1,
         1
      ],
      "ori_name": "BatchNormalization_69"
   },
   "Add_70_1": {
      "layer_index": 38,
      "name": "Add_70_1",
      "operation": "element_wise_add",
      "device": "npu",
      "file_list": {
         "input_activation1": "Add_70_1_input_activation1.npy",
         "input_activation2": "Add_70_1_input_activation2.npy",
         "output_activation1": "Add_70_1_output_activation1.npy"
      },
      "previous_layer": [
         "Conv_68",
         "dequantize_Add_70_input_2_1"
      ],
      "next_layer": [
         "Conv_72",
         "dequantize_Add_77_input_2_1"
      ],
      "input_shape": [
         [
            1,
            256,
            14,
            14
         ],
         [
            1,
            256,
            14,
            14
         ]
      ],
      "output_shape": [
         [
            1,
            256,
            14,
            14
         ]
      ],
      "input_dtype": [
         "float16",
         "float16"
      ],
      "output_dtype": [
         "int8"
      ],
      "tensor0_lut": [
         1,
         1,
         1
      ],
      "tensor1_lut": [
         1,
         1,
         1
      ],
      "tensor_mode": 0,
      "module_list": {
         "pre_cal": {
            "input_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ],
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "output_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ],
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "requan_scale_a": 1,
            "requan_zp_a": 0,
            "requan_scale_b": 1,
            "requan_zp_b": 0
         },
         "fp32_sum_sub_group0": {
            "sumsub_group_mode": "add",
            "sumsub_group_b_mux": "vector",
            "input_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ],
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "output_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ]
         },
         "relu_group": {
            "input_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "output_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ]
         },
         "post_cal": {
            "mul_k": 50.45851805951721,
            "sum_b": -128.0,
            "sumsub_mode": "add",
            "carry_sel": "round",
            "input_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "output_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ]
         }
      },
      "ori_name": "Relu_71",
      "input_batchdim": [
         0,
         0
      ],
      "output_batchdim": [
         0
      ]
   },
   "Conv_72": {
      "layer_index": 39,
      "name": "Conv_72",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "int8"
      ],
      "input_shape": [
         [
            1,
            256,
            14,
            14
         ],
         [
            256,
            256,
            3,
            3
         ]
      ],
      "output_shape": [
         [
            1,
            256,
            14,
            14
         ]
      ],
      "quant_info": {
         "input_scale1": 0.01981825940310955,
         "input_zero_point1": 128.0,
         "output_scale": 136.70978503837992,
         "output_zero_point": -128.0,
         "round_type": "round"
      },
      "previous_layer": [
         "Add_70_1",
         "constant_layer3_2_conv1_weight"
      ],
      "next_layer": [
         "Conv_75"
      ],
      "file_list": {
         "input_activation1": "Conv_72_input_activation1.npy",
         "input_activation2": "Conv_72_input_activation2.npy",
         "output_activation1": "Conv_72_output_activation1.npy",
         "k": "Conv_72_k.npy",
         "b": "Conv_72_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": "relu",
      "activation_attr": null,
      "kernel_size": [
         3,
         3
      ],
      "padding": [
         1,
         1,
         1,
         1
      ],
      "stride": [
         1,
         1
      ],
      "ori_name": "Relu_74"
   },
   "dequantize_Add_77_input_2_1": {
      "layer_index": 40,
      "name": "dequantize_Add_77_input_2_1",
      "operation": "quantize",
      "device": "npu",
      "input_dtype": [
         "int8"
      ],
      "output_dtype": [
         "float16"
      ],
      "input_shape": [
         [
            1,
            256,
            14,
            14
         ]
      ],
      "output_shape": [
         [
            1,
            256,
            14,
            14
         ]
      ],
      "file_list": {
         "input_activation1": "dequantize_Add_77_input_2_1_input_activation1.npy",
         "output_activation1": "dequantize_Add_77_input_2_1_output_activation1.npy"
      },
      "previous_layer": [
         "Add_70_1"
      ],
      "next_layer": [
         "Add_77_1"
      ],
      "tensor0_lut": [
         1,
         1,
         1
      ],
      "tensor_mode": 0,
      "module_list": {
         "pre_cal": {
            "requan_scale_a": 0.01981825940310955,
            "requan_zp_a": 2.5367372035980225,
            "input_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "output_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ]
         },
         "post_cal": {
            "input_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "output_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "mul_k": 1,
            "sum_b": 0,
            "sumsub_mode": "add"
         }
      },
      "input_batchdim": [
         0
      ],
      "output_batchdim": [
         0
      ]
   },
   "Conv_75": {
      "layer_index": 41,
      "name": "Conv_75",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "float16"
      ],
      "input_shape": [
         [
            1,
            256,
            14,
            14
         ],
         [
            256,
            256,
            3,
            3
         ]
      ],
      "output_shape": [
         [
            1,
            256,
            14,
            14
         ]
      ],
      "quant_info": {
         "input_scale1": 0.007314765360206366,
         "input_zero_point1": 128.0
      },
      "previous_layer": [
         "Conv_72",
         "constant_layer3_2_conv2_weight"
      ],
      "next_layer": [
         "Add_77_1"
      ],
      "file_list": {
         "input_activation1": "Conv_75_input_activation1.npy",
         "input_activation2": "Conv_75_input_activation2.npy",
         "output_activation1": "Conv_75_output_activation1.npy",
         "k": "Conv_75_k.npy",
         "b": "Conv_75_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": null,
      "activation_attr": null,
      "kernel_size": [
         3,
         3
      ],
      "padding": [
         1,
         1,
         1,
         1
      ],
      "stride": [
         1,
         1
      ],
      "ori_name": "BatchNormalization_76"
   },
   "Add_77_1": {
      "layer_index": 42,
      "name": "Add_77_1",
      "operation": "element_wise_add",
      "device": "npu",
      "file_list": {
         "input_activation1": "Add_77_1_input_activation1.npy",
         "input_activation2": "Add_77_1_input_activation2.npy",
         "output_activation1": "Add_77_1_output_activation1.npy"
      },
      "previous_layer": [
         "Conv_75",
         "dequantize_Add_77_input_2_1"
      ],
      "next_layer": [
         "Conv_79",
         "dequantize_Add_84_input_2_1"
      ],
      "input_shape": [
         [
            1,
            256,
            14,
            14
         ],
         [
            1,
            256,
            14,
            14
         ]
      ],
      "output_shape": [
         [
            1,
            256,
            14,
            14
         ]
      ],
      "input_dtype": [
         "float16",
         "float16"
      ],
      "output_dtype": [
         "int8"
      ],
      "tensor0_lut": [
         1,
         1,
         1
      ],
      "tensor1_lut": [
         1,
         1,
         1
      ],
      "tensor_mode": 0,
      "module_list": {
         "pre_cal": {
            "input_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ],
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "output_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ],
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "requan_scale_a": 1,
            "requan_zp_a": 0,
            "requan_scale_b": 1,
            "requan_zp_b": 0
         },
         "fp32_sum_sub_group0": {
            "sumsub_group_mode": "add",
            "sumsub_group_b_mux": "vector",
            "input_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ],
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "output_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ]
         },
         "relu_group": {
            "input_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "output_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ]
         },
         "post_cal": {
            "mul_k": 40.93685995518433,
            "sum_b": -128.0,
            "sumsub_mode": "add",
            "carry_sel": "round",
            "input_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "output_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ]
         }
      },
      "ori_name": "Relu_78",
      "input_batchdim": [
         0,
         0
      ],
      "output_batchdim": [
         0
      ]
   },
   "Conv_79": {
      "layer_index": 43,
      "name": "Conv_79",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "int8"
      ],
      "input_shape": [
         [
            1,
            256,
            14,
            14
         ],
         [
            256,
            256,
            3,
            3
         ]
      ],
      "output_shape": [
         [
            1,
            256,
            14,
            14
         ]
      ],
      "quant_info": {
         "input_scale1": 0.024427862837910652,
         "input_zero_point1": 128.0,
         "output_scale": 151.6381456268285,
         "output_zero_point": -128.0,
         "round_type": "round"
      },
      "previous_layer": [
         "Add_77_1",
         "constant_layer3_3_conv1_weight"
      ],
      "next_layer": [
         "Conv_82"
      ],
      "file_list": {
         "input_activation1": "Conv_79_input_activation1.npy",
         "input_activation2": "Conv_79_input_activation2.npy",
         "output_activation1": "Conv_79_output_activation1.npy",
         "k": "Conv_79_k.npy",
         "b": "Conv_79_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": "relu",
      "activation_attr": null,
      "kernel_size": [
         3,
         3
      ],
      "padding": [
         1,
         1,
         1,
         1
      ],
      "stride": [
         1,
         1
      ],
      "ori_name": "Relu_81"
   },
   "dequantize_Add_84_input_2_1": {
      "layer_index": 44,
      "name": "dequantize_Add_84_input_2_1",
      "operation": "quantize",
      "device": "npu",
      "input_dtype": [
         "int8"
      ],
      "output_dtype": [
         "float16"
      ],
      "input_shape": [
         [
            1,
            256,
            14,
            14
         ]
      ],
      "output_shape": [
         [
            1,
            256,
            14,
            14
         ]
      ],
      "file_list": {
         "input_activation1": "dequantize_Add_84_input_2_1_input_activation1.npy",
         "output_activation1": "dequantize_Add_84_input_2_1_output_activation1.npy"
      },
      "previous_layer": [
         "Add_77_1"
      ],
      "next_layer": [
         "Add_84_1"
      ],
      "tensor0_lut": [
         1,
         1,
         1
      ],
      "tensor_mode": 0,
      "module_list": {
         "pre_cal": {
            "requan_scale_a": 0.024427862837910652,
            "requan_zp_a": 3.1267664432525635,
            "input_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "output_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ]
         },
         "post_cal": {
            "input_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "output_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "mul_k": 1,
            "sum_b": 0,
            "sumsub_mode": "add"
         }
      },
      "input_batchdim": [
         0
      ],
      "output_batchdim": [
         0
      ]
   },
   "Conv_82": {
      "layer_index": 45,
      "name": "Conv_82",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "float16"
      ],
      "input_shape": [
         [
            1,
            256,
            14,
            14
         ],
         [
            256,
            256,
            3,
            3
         ]
      ],
      "output_shape": [
         [
            1,
            256,
            14,
            14
         ]
      ],
      "quant_info": {
         "input_scale1": 0.006594646722078323,
         "input_zero_point1": 128.0
      },
      "previous_layer": [
         "Conv_79",
         "constant_layer3_3_conv2_weight"
      ],
      "next_layer": [
         "Add_84_1"
      ],
      "file_list": {
         "input_activation1": "Conv_82_input_activation1.npy",
         "input_activation2": "Conv_82_input_activation2.npy",
         "output_activation1": "Conv_82_output_activation1.npy",
         "k": "Conv_82_k.npy",
         "b": "Conv_82_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": null,
      "activation_attr": null,
      "kernel_size": [
         3,
         3
      ],
      "padding": [
         1,
         1,
         1,
         1
      ],
      "stride": [
         1,
         1
      ],
      "ori_name": "BatchNormalization_83"
   },
   "Add_84_1": {
      "layer_index": 46,
      "name": "Add_84_1",
      "operation": "element_wise_add",
      "device": "npu",
      "file_list": {
         "input_activation1": "Add_84_1_input_activation1.npy",
         "input_activation2": "Add_84_1_input_activation2.npy",
         "output_activation1": "Add_84_1_output_activation1.npy"
      },
      "previous_layer": [
         "Conv_82",
         "dequantize_Add_84_input_2_1"
      ],
      "next_layer": [
         "Conv_86",
         "dequantize_Add_91_input_2_1"
      ],
      "input_shape": [
         [
            1,
            256,
            14,
            14
         ],
         [
            1,
            256,
            14,
            14
         ]
      ],
      "output_shape": [
         [
            1,
            256,
            14,
            14
         ]
      ],
      "input_dtype": [
         "float16",
         "float16"
      ],
      "output_dtype": [
         "int8"
      ],
      "tensor0_lut": [
         1,
         1,
         1
      ],
      "tensor1_lut": [
         1,
         1,
         1
      ],
      "tensor_mode": 0,
      "module_list": {
         "pre_cal": {
            "input_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ],
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "output_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ],
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "requan_scale_a": 1,
            "requan_zp_a": 0,
            "requan_scale_b": 1,
            "requan_zp_b": 0
         },
         "fp32_sum_sub_group0": {
            "sumsub_group_mode": "add",
            "sumsub_group_b_mux": "vector",
            "input_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ],
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "output_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ]
         },
         "relu_group": {
            "input_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "output_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ]
         },
         "post_cal": {
            "mul_k": 52.106219756324954,
            "sum_b": -128.0,
            "sumsub_mode": "add",
            "carry_sel": "round",
            "input_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "output_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ]
         }
      },
      "ori_name": "Relu_85",
      "input_batchdim": [
         0,
         0
      ],
      "output_batchdim": [
         0
      ]
   },
   "Conv_86": {
      "layer_index": 47,
      "name": "Conv_86",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "int8"
      ],
      "input_shape": [
         [
            1,
            256,
            14,
            14
         ],
         [
            256,
            256,
            3,
            3
         ]
      ],
      "output_shape": [
         [
            1,
            256,
            14,
            14
         ]
      ],
      "quant_info": {
         "input_scale1": 0.019191566854715347,
         "input_zero_point1": 128.0,
         "output_scale": 96.97655935656387,
         "output_zero_point": -128.0,
         "round_type": "round"
      },
      "previous_layer": [
         "Add_84_1",
         "constant_layer3_4_conv1_weight"
      ],
      "next_layer": [
         "Conv_89"
      ],
      "file_list": {
         "input_activation1": "Conv_86_input_activation1.npy",
         "input_activation2": "Conv_86_input_activation2.npy",
         "output_activation1": "Conv_86_output_activation1.npy",
         "k": "Conv_86_k.npy",
         "b": "Conv_86_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": "relu",
      "activation_attr": null,
      "kernel_size": [
         3,
         3
      ],
      "padding": [
         1,
         1,
         1,
         1
      ],
      "stride": [
         1,
         1
      ],
      "ori_name": "Relu_88"
   },
   "dequantize_Add_91_input_2_1": {
      "layer_index": 48,
      "name": "dequantize_Add_91_input_2_1",
      "operation": "quantize",
      "device": "npu",
      "input_dtype": [
         "int8"
      ],
      "output_dtype": [
         "float16"
      ],
      "input_shape": [
         [
            1,
            256,
            14,
            14
         ]
      ],
      "output_shape": [
         [
            1,
            256,
            14,
            14
         ]
      ],
      "file_list": {
         "input_activation1": "dequantize_Add_91_input_2_1_input_activation1.npy",
         "output_activation1": "dequantize_Add_91_input_2_1_output_activation1.npy"
      },
      "previous_layer": [
         "Add_84_1"
      ],
      "next_layer": [
         "Add_91_1"
      ],
      "tensor0_lut": [
         1,
         1,
         1
      ],
      "tensor_mode": 0,
      "module_list": {
         "pre_cal": {
            "requan_scale_a": 0.019191566854715347,
            "requan_zp_a": 2.4565205574035645,
            "input_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "output_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ]
         },
         "post_cal": {
            "input_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "output_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "mul_k": 1,
            "sum_b": 0,
            "sumsub_mode": "add"
         }
      },
      "input_batchdim": [
         0
      ],
      "output_batchdim": [
         0
      ]
   },
   "Conv_89": {
      "layer_index": 49,
      "name": "Conv_89",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "float16"
      ],
      "input_shape": [
         [
            1,
            256,
            14,
            14
         ],
         [
            256,
            256,
            3,
            3
         ]
      ],
      "output_shape": [
         [
            1,
            256,
            14,
            14
         ]
      ],
      "quant_info": {
         "input_scale1": 0.010311770252883434,
         "input_zero_point1": 128.0
      },
      "previous_layer": [
         "Conv_86",
         "constant_layer3_4_conv2_weight"
      ],
      "next_layer": [
         "Add_91_1"
      ],
      "file_list": {
         "input_activation1": "Conv_89_input_activation1.npy",
         "input_activation2": "Conv_89_input_activation2.npy",
         "output_activation1": "Conv_89_output_activation1.npy",
         "k": "Conv_89_k.npy",
         "b": "Conv_89_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": null,
      "activation_attr": null,
      "kernel_size": [
         3,
         3
      ],
      "padding": [
         1,
         1,
         1,
         1
      ],
      "stride": [
         1,
         1
      ],
      "ori_name": "BatchNormalization_90"
   },
   "Add_91_1": {
      "layer_index": 50,
      "name": "Add_91_1",
      "operation": "element_wise_add",
      "device": "npu",
      "file_list": {
         "input_activation1": "Add_91_1_input_activation1.npy",
         "input_activation2": "Add_91_1_input_activation2.npy",
         "output_activation1": "Add_91_1_output_activation1.npy"
      },
      "previous_layer": [
         "Conv_89",
         "dequantize_Add_91_input_2_1"
      ],
      "next_layer": [
         "Conv_93",
         "dequantize_Add_98_input_2_1"
      ],
      "input_shape": [
         [
            1,
            256,
            14,
            14
         ],
         [
            1,
            256,
            14,
            14
         ]
      ],
      "output_shape": [
         [
            1,
            256,
            14,
            14
         ]
      ],
      "input_dtype": [
         "float16",
         "float16"
      ],
      "output_dtype": [
         "int8"
      ],
      "tensor0_lut": [
         1,
         1,
         1
      ],
      "tensor1_lut": [
         1,
         1,
         1
      ],
      "tensor_mode": 0,
      "module_list": {
         "pre_cal": {
            "input_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ],
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "output_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ],
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "requan_scale_a": 1,
            "requan_zp_a": 0,
            "requan_scale_b": 1,
            "requan_zp_b": 0
         },
         "fp32_sum_sub_group0": {
            "sumsub_group_mode": "add",
            "sumsub_group_b_mux": "vector",
            "input_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ],
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "output_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ]
         },
         "relu_group": {
            "input_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "output_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ]
         },
         "post_cal": {
            "mul_k": 37.97916091006084,
            "sum_b": -128.0,
            "sumsub_mode": "add",
            "carry_sel": "round",
            "input_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "output_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ]
         }
      },
      "ori_name": "Relu_92",
      "input_batchdim": [
         0,
         0
      ],
      "output_batchdim": [
         0
      ]
   },
   "Conv_93": {
      "layer_index": 51,
      "name": "Conv_93",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "int8"
      ],
      "input_shape": [
         [
            1,
            256,
            14,
            14
         ],
         [
            256,
            256,
            3,
            3
         ]
      ],
      "output_shape": [
         [
            1,
            256,
            14,
            14
         ]
      ],
      "quant_info": {
         "input_scale1": 0.02633022889494896,
         "input_zero_point1": 128.0,
         "output_scale": 110.77268848264762,
         "output_zero_point": -128.0,
         "round_type": "round"
      },
      "previous_layer": [
         "Add_91_1",
         "constant_layer3_5_conv1_weight"
      ],
      "next_layer": [
         "Conv_96"
      ],
      "file_list": {
         "input_activation1": "Conv_93_input_activation1.npy",
         "input_activation2": "Conv_93_input_activation2.npy",
         "output_activation1": "Conv_93_output_activation1.npy",
         "k": "Conv_93_k.npy",
         "b": "Conv_93_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": "relu",
      "activation_attr": null,
      "kernel_size": [
         3,
         3
      ],
      "padding": [
         1,
         1,
         1,
         1
      ],
      "stride": [
         1,
         1
      ],
      "ori_name": "Relu_95"
   },
   "dequantize_Add_98_input_2_1": {
      "layer_index": 52,
      "name": "dequantize_Add_98_input_2_1",
      "operation": "quantize",
      "device": "npu",
      "input_dtype": [
         "int8"
      ],
      "output_dtype": [
         "float16"
      ],
      "input_shape": [
         [
            1,
            256,
            14,
            14
         ]
      ],
      "output_shape": [
         [
            1,
            256,
            14,
            14
         ]
      ],
      "file_list": {
         "input_activation1": "dequantize_Add_98_input_2_1_input_activation1.npy",
         "output_activation1": "dequantize_Add_98_input_2_1_output_activation1.npy"
      },
      "previous_layer": [
         "Add_91_1"
      ],
      "next_layer": [
         "Add_98_1"
      ],
      "tensor0_lut": [
         1,
         1,
         1
      ],
      "tensor_mode": 0,
      "module_list": {
         "pre_cal": {
            "requan_scale_a": 0.02633022889494896,
            "requan_zp_a": 3.370269298553467,
            "input_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "output_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ]
         },
         "post_cal": {
            "input_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "output_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "mul_k": 1,
            "sum_b": 0,
            "sumsub_mode": "add"
         }
      },
      "input_batchdim": [
         0
      ],
      "output_batchdim": [
         0
      ]
   },
   "Conv_96": {
      "layer_index": 53,
      "name": "Conv_96",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "float16"
      ],
      "input_shape": [
         [
            1,
            256,
            14,
            14
         ],
         [
            256,
            256,
            3,
            3
         ]
      ],
      "output_shape": [
         [
            1,
            256,
            14,
            14
         ]
      ],
      "quant_info": {
         "input_scale1": 0.009027495980262756,
         "input_zero_point1": 128.0
      },
      "previous_layer": [
         "Conv_93",
         "constant_layer3_5_conv2_weight"
      ],
      "next_layer": [
         "Add_98_1"
      ],
      "file_list": {
         "input_activation1": "Conv_96_input_activation1.npy",
         "input_activation2": "Conv_96_input_activation2.npy",
         "output_activation1": "Conv_96_output_activation1.npy",
         "k": "Conv_96_k.npy",
         "b": "Conv_96_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": null,
      "activation_attr": null,
      "kernel_size": [
         3,
         3
      ],
      "padding": [
         1,
         1,
         1,
         1
      ],
      "stride": [
         1,
         1
      ],
      "ori_name": "BatchNormalization_97"
   },
   "Add_98_1": {
      "layer_index": 54,
      "name": "Add_98_1",
      "operation": "element_wise_add",
      "device": "npu",
      "file_list": {
         "input_activation1": "Add_98_1_input_activation1.npy",
         "input_activation2": "Add_98_1_input_activation2.npy",
         "output_activation1": "Add_98_1_output_activation1.npy"
      },
      "previous_layer": [
         "Conv_96",
         "dequantize_Add_98_input_2_1"
      ],
      "next_layer": [
         "Conv_100",
         "Conv_105"
      ],
      "input_shape": [
         [
            1,
            256,
            14,
            14
         ],
         [
            1,
            256,
            14,
            14
         ]
      ],
      "output_shape": [
         [
            1,
            256,
            14,
            14
         ]
      ],
      "input_dtype": [
         "float16",
         "float16"
      ],
      "output_dtype": [
         "int8"
      ],
      "tensor0_lut": [
         1,
         1,
         1
      ],
      "tensor1_lut": [
         1,
         1,
         1
      ],
      "tensor_mode": 0,
      "module_list": {
         "pre_cal": {
            "input_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ],
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "output_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ],
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "requan_scale_a": 1,
            "requan_zp_a": 0,
            "requan_scale_b": 1,
            "requan_zp_b": 0
         },
         "fp32_sum_sub_group0": {
            "sumsub_group_mode": "add",
            "sumsub_group_b_mux": "vector",
            "input_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ],
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "output_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ]
         },
         "relu_group": {
            "input_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "output_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ]
         },
         "post_cal": {
            "mul_k": 40.625442636249026,
            "sum_b": -128.0,
            "sumsub_mode": "add",
            "carry_sel": "round",
            "input_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ],
            "output_shape": [
               [
                  1,
                  256,
                  14,
                  14
               ]
            ]
         }
      },
      "ori_name": "Relu_99",
      "input_batchdim": [
         0,
         0
      ],
      "output_batchdim": [
         0
      ]
   },
   "Conv_100": {
      "layer_index": 55,
      "name": "Conv_100",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "int8"
      ],
      "input_shape": [
         [
            1,
            256,
            14,
            14
         ],
         [
            512,
            256,
            3,
            3
         ]
      ],
      "output_shape": [
         [
            1,
            512,
            7,
            7
         ]
      ],
      "quant_info": {
         "input_scale1": 0.02461511641740799,
         "input_zero_point1": 128.0,
         "output_scale": 124.51205964286133,
         "output_zero_point": -128.0,
         "round_type": "round"
      },
      "previous_layer": [
         "Add_98_1",
         "constant_layer4_0_conv1_weight"
      ],
      "next_layer": [
         "Conv_103"
      ],
      "file_list": {
         "input_activation1": "Conv_100_input_activation1.npy",
         "input_activation2": "Conv_100_input_activation2.npy",
         "output_activation1": "Conv_100_output_activation1.npy",
         "k": "Conv_100_k.npy",
         "b": "Conv_100_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": "relu",
      "activation_attr": null,
      "kernel_size": [
         3,
         3
      ],
      "padding": [
         1,
         1,
         1,
         1
      ],
      "stride": [
         2,
         2
      ],
      "ori_name": "Relu_102"
   },
   "Conv_105": {
      "layer_index": 56,
      "name": "Conv_105",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "float16"
      ],
      "input_shape": [
         [
            1,
            256,
            14,
            14
         ],
         [
            512,
            256,
            1,
            1
         ]
      ],
      "output_shape": [
         [
            1,
            512,
            7,
            7
         ]
      ],
      "quant_info": {
         "input_scale1": 0.02461511641740799,
         "input_zero_point1": 128.0
      },
      "previous_layer": [
         "Add_98_1",
         "constant_layer4_0_downsample_0_weight"
      ],
      "next_layer": [
         "Add_107_1"
      ],
      "file_list": {
         "input_activation1": "Conv_105_input_activation1.npy",
         "input_activation2": "Conv_105_input_activation2.npy",
         "output_activation1": "Conv_105_output_activation1.npy",
         "k": "Conv_105_k.npy",
         "b": "Conv_105_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": null,
      "activation_attr": null,
      "kernel_size": [
         1,
         1
      ],
      "padding": [
         0,
         0,
         0,
         0
      ],
      "stride": [
         2,
         2
      ],
      "ori_name": "BatchNormalization_106"
   },
   "Conv_103": {
      "layer_index": 57,
      "name": "Conv_103",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "float16"
      ],
      "input_shape": [
         [
            1,
            512,
            7,
            7
         ],
         [
            512,
            512,
            3,
            3
         ]
      ],
      "output_shape": [
         [
            1,
            512,
            7,
            7
         ]
      ],
      "quant_info": {
         "input_scale1": 0.008031350560486317,
         "input_zero_point1": 128.0
      },
      "previous_layer": [
         "Conv_100",
         "constant_layer4_0_conv2_weight"
      ],
      "next_layer": [
         "Add_107_1"
      ],
      "file_list": {
         "input_activation1": "Conv_103_input_activation1.npy",
         "input_activation2": "Conv_103_input_activation2.npy",
         "output_activation1": "Conv_103_output_activation1.npy",
         "k": "Conv_103_k.npy",
         "b": "Conv_103_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": null,
      "activation_attr": null,
      "kernel_size": [
         3,
         3
      ],
      "padding": [
         1,
         1,
         1,
         1
      ],
      "stride": [
         1,
         1
      ],
      "ori_name": "BatchNormalization_104"
   },
   "Add_107_1": {
      "layer_index": 58,
      "name": "Add_107_1",
      "operation": "element_wise_add",
      "device": "npu",
      "file_list": {
         "input_activation1": "Add_107_1_input_activation1.npy",
         "input_activation2": "Add_107_1_input_activation2.npy",
         "output_activation1": "Add_107_1_output_activation1.npy"
      },
      "previous_layer": [
         "Conv_103",
         "Conv_105"
      ],
      "next_layer": [
         "Conv_109",
         "dequantize_Add_114_input_2_1"
      ],
      "input_shape": [
         [
            1,
            512,
            7,
            7
         ],
         [
            1,
            512,
            7,
            7
         ]
      ],
      "output_shape": [
         [
            1,
            512,
            7,
            7
         ]
      ],
      "input_dtype": [
         "float16",
         "float16"
      ],
      "output_dtype": [
         "int8"
      ],
      "tensor0_lut": [
         1,
         1,
         1
      ],
      "tensor1_lut": [
         1,
         1,
         1
      ],
      "tensor_mode": 0,
      "module_list": {
         "pre_cal": {
            "input_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ],
               [
                  1,
                  512,
                  7,
                  7
               ]
            ],
            "output_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ],
               [
                  1,
                  512,
                  7,
                  7
               ]
            ],
            "requan_scale_a": 1,
            "requan_zp_a": 0,
            "requan_scale_b": 1,
            "requan_zp_b": 0
         },
         "fp32_sum_sub_group0": {
            "sumsub_group_mode": "add",
            "sumsub_group_b_mux": "vector",
            "input_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ],
               [
                  1,
                  512,
                  7,
                  7
               ]
            ],
            "output_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ]
            ]
         },
         "relu_group": {
            "input_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ]
            ],
            "output_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ]
            ]
         },
         "post_cal": {
            "mul_k": 25.38316577046172,
            "sum_b": -128.0,
            "sumsub_mode": "add",
            "carry_sel": "round",
            "input_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ]
            ],
            "output_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ]
            ]
         }
      },
      "ori_name": "Relu_108",
      "input_batchdim": [
         0,
         0
      ],
      "output_batchdim": [
         0
      ]
   },
   "Conv_109": {
      "layer_index": 59,
      "name": "Conv_109",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "int8"
      ],
      "input_shape": [
         [
            1,
            512,
            7,
            7
         ],
         [
            512,
            512,
            3,
            3
         ]
      ],
      "output_shape": [
         [
            1,
            512,
            7,
            7
         ]
      ],
      "quant_info": {
         "input_scale1": 0.03939618915319443,
         "input_zero_point1": 128.0,
         "output_scale": 129.11297227600215,
         "output_zero_point": -128.0,
         "round_type": "round"
      },
      "previous_layer": [
         "Add_107_1",
         "constant_layer4_1_conv1_weight"
      ],
      "next_layer": [
         "Conv_112"
      ],
      "file_list": {
         "input_activation1": "Conv_109_input_activation1.npy",
         "input_activation2": "Conv_109_input_activation2.npy",
         "output_activation1": "Conv_109_output_activation1.npy",
         "k": "Conv_109_k.npy",
         "b": "Conv_109_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": "relu",
      "activation_attr": null,
      "kernel_size": [
         3,
         3
      ],
      "padding": [
         1,
         1,
         1,
         1
      ],
      "stride": [
         1,
         1
      ],
      "ori_name": "Relu_111"
   },
   "dequantize_Add_114_input_2_1": {
      "layer_index": 60,
      "name": "dequantize_Add_114_input_2_1",
      "operation": "quantize",
      "device": "npu",
      "input_dtype": [
         "int8"
      ],
      "output_dtype": [
         "float16"
      ],
      "input_shape": [
         [
            1,
            512,
            7,
            7
         ]
      ],
      "output_shape": [
         [
            1,
            512,
            7,
            7
         ]
      ],
      "file_list": {
         "input_activation1": "dequantize_Add_114_input_2_1_input_activation1.npy",
         "output_activation1": "dequantize_Add_114_input_2_1_output_activation1.npy"
      },
      "previous_layer": [
         "Add_107_1"
      ],
      "next_layer": [
         "Add_114_1"
      ],
      "tensor0_lut": [
         1,
         1,
         1
      ],
      "tensor_mode": 0,
      "module_list": {
         "pre_cal": {
            "requan_scale_a": 0.03939618915319443,
            "requan_zp_a": 5.042712211608887,
            "input_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ]
            ],
            "output_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ]
            ]
         },
         "post_cal": {
            "input_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ]
            ],
            "output_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ]
            ],
            "mul_k": 1,
            "sum_b": 0,
            "sumsub_mode": "add"
         }
      },
      "input_batchdim": [
         0
      ],
      "output_batchdim": [
         0
      ]
   },
   "Conv_112": {
      "layer_index": 61,
      "name": "Conv_112",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "float16"
      ],
      "input_shape": [
         [
            1,
            512,
            7,
            7
         ],
         [
            512,
            512,
            3,
            3
         ]
      ],
      "output_shape": [
         [
            1,
            512,
            7,
            7
         ]
      ],
      "quant_info": {
         "input_scale1": 0.00774515513330698,
         "input_zero_point1": 128.0
      },
      "previous_layer": [
         "Conv_109",
         "constant_layer4_1_conv2_weight"
      ],
      "next_layer": [
         "Add_114_1"
      ],
      "file_list": {
         "input_activation1": "Conv_112_input_activation1.npy",
         "input_activation2": "Conv_112_input_activation2.npy",
         "output_activation1": "Conv_112_output_activation1.npy",
         "k": "Conv_112_k.npy",
         "b": "Conv_112_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": null,
      "activation_attr": null,
      "kernel_size": [
         3,
         3
      ],
      "padding": [
         1,
         1,
         1,
         1
      ],
      "stride": [
         1,
         1
      ],
      "ori_name": "BatchNormalization_113"
   },
   "Add_114_1": {
      "layer_index": 62,
      "name": "Add_114_1",
      "operation": "element_wise_add",
      "device": "npu",
      "file_list": {
         "input_activation1": "Add_114_1_input_activation1.npy",
         "input_activation2": "Add_114_1_input_activation2.npy",
         "output_activation1": "Add_114_1_output_activation1.npy"
      },
      "previous_layer": [
         "Conv_112",
         "dequantize_Add_114_input_2_1"
      ],
      "next_layer": [
         "Conv_116",
         "dequantize_Add_121_input_2_1"
      ],
      "input_shape": [
         [
            1,
            512,
            7,
            7
         ],
         [
            1,
            512,
            7,
            7
         ]
      ],
      "output_shape": [
         [
            1,
            512,
            7,
            7
         ]
      ],
      "input_dtype": [
         "float16",
         "float16"
      ],
      "output_dtype": [
         "int8"
      ],
      "tensor0_lut": [
         1,
         1,
         1
      ],
      "tensor1_lut": [
         1,
         1,
         1
      ],
      "tensor_mode": 0,
      "module_list": {
         "pre_cal": {
            "input_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ],
               [
                  1,
                  512,
                  7,
                  7
               ]
            ],
            "output_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ],
               [
                  1,
                  512,
                  7,
                  7
               ]
            ],
            "requan_scale_a": 1,
            "requan_zp_a": 0,
            "requan_scale_b": 1,
            "requan_zp_b": 0
         },
         "fp32_sum_sub_group0": {
            "sumsub_group_mode": "add",
            "sumsub_group_b_mux": "vector",
            "input_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ],
               [
                  1,
                  512,
                  7,
                  7
               ]
            ],
            "output_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ]
            ]
         },
         "relu_group": {
            "input_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ]
            ],
            "output_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ]
            ]
         },
         "post_cal": {
            "mul_k": 18.635268766444284,
            "sum_b": -128.0,
            "sumsub_mode": "add",
            "carry_sel": "round",
            "input_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ]
            ],
            "output_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ]
            ]
         }
      },
      "ori_name": "Relu_115",
      "input_batchdim": [
         0,
         0
      ],
      "output_batchdim": [
         0
      ]
   },
   "Conv_116": {
      "layer_index": 63,
      "name": "Conv_116",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "int8"
      ],
      "input_shape": [
         [
            1,
            512,
            7,
            7
         ],
         [
            512,
            512,
            3,
            3
         ]
      ],
      "output_shape": [
         [
            1,
            512,
            7,
            7
         ]
      ],
      "quant_info": {
         "input_scale1": 0.053661689162254333,
         "input_zero_point1": 128.0,
         "output_scale": 170.18781650419913,
         "output_zero_point": -128.0,
         "round_type": "round"
      },
      "previous_layer": [
         "Add_114_1",
         "constant_layer4_2_conv1_weight"
      ],
      "next_layer": [
         "Conv_119"
      ],
      "file_list": {
         "input_activation1": "Conv_116_input_activation1.npy",
         "input_activation2": "Conv_116_input_activation2.npy",
         "output_activation1": "Conv_116_output_activation1.npy",
         "k": "Conv_116_k.npy",
         "b": "Conv_116_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": "relu",
      "activation_attr": null,
      "kernel_size": [
         3,
         3
      ],
      "padding": [
         1,
         1,
         1,
         1
      ],
      "stride": [
         1,
         1
      ],
      "ori_name": "Relu_118"
   },
   "dequantize_Add_121_input_2_1": {
      "layer_index": 64,
      "name": "dequantize_Add_121_input_2_1",
      "operation": "quantize",
      "device": "npu",
      "input_dtype": [
         "int8"
      ],
      "output_dtype": [
         "float16"
      ],
      "input_shape": [
         [
            1,
            512,
            7,
            7
         ]
      ],
      "output_shape": [
         [
            1,
            512,
            7,
            7
         ]
      ],
      "file_list": {
         "input_activation1": "dequantize_Add_121_input_2_1_input_activation1.npy",
         "output_activation1": "dequantize_Add_121_input_2_1_output_activation1.npy"
      },
      "previous_layer": [
         "Add_114_1"
      ],
      "next_layer": [
         "Add_121_1"
      ],
      "tensor0_lut": [
         1,
         1,
         1
      ],
      "tensor_mode": 0,
      "module_list": {
         "pre_cal": {
            "requan_scale_a": 0.053661689162254333,
            "requan_zp_a": 6.868696212768555,
            "input_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ]
            ],
            "output_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ]
            ]
         },
         "post_cal": {
            "input_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ]
            ],
            "output_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ]
            ],
            "mul_k": 1,
            "sum_b": 0,
            "sumsub_mode": "add"
         }
      },
      "input_batchdim": [
         0
      ],
      "output_batchdim": [
         0
      ]
   },
   "Conv_119": {
      "layer_index": 65,
      "name": "Conv_119",
      "operation": "conv2d",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "float16"
      ],
      "input_shape": [
         [
            1,
            512,
            7,
            7
         ],
         [
            512,
            512,
            3,
            3
         ]
      ],
      "output_shape": [
         [
            1,
            512,
            7,
            7
         ]
      ],
      "quant_info": {
         "input_scale1": 0.005875861272215843,
         "input_zero_point1": 128.0
      },
      "previous_layer": [
         "Conv_116",
         "constant_layer4_2_conv2_weight"
      ],
      "next_layer": [
         "Add_121_1"
      ],
      "file_list": {
         "input_activation1": "Conv_119_input_activation1.npy",
         "input_activation2": "Conv_119_input_activation2.npy",
         "output_activation1": "Conv_119_output_activation1.npy",
         "k": "Conv_119_k.npy",
         "b": "Conv_119_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": null,
      "activation_attr": null,
      "kernel_size": [
         3,
         3
      ],
      "padding": [
         1,
         1,
         1,
         1
      ],
      "stride": [
         1,
         1
      ],
      "ori_name": "BatchNormalization_120"
   },
   "Add_121_1": {
      "layer_index": 66,
      "name": "Add_121_1",
      "operation": "element_wise_add",
      "device": "npu",
      "file_list": {
         "input_activation1": "Add_121_1_input_activation1.npy",
         "input_activation2": "Add_121_1_input_activation2.npy",
         "output_activation1": "Add_121_1_output_activation1.npy"
      },
      "previous_layer": [
         "Conv_119",
         "dequantize_Add_121_input_2_1"
      ],
      "next_layer": [
         "GlobalAveragePool_123_1"
      ],
      "input_shape": [
         [
            1,
            512,
            7,
            7
         ],
         [
            1,
            512,
            7,
            7
         ]
      ],
      "output_shape": [
         [
            1,
            512,
            7,
            7
         ]
      ],
      "input_dtype": [
         "float16",
         "float16"
      ],
      "output_dtype": [
         "int8"
      ],
      "tensor0_lut": [
         1,
         1,
         1
      ],
      "tensor1_lut": [
         1,
         1,
         1
      ],
      "tensor_mode": 0,
      "module_list": {
         "pre_cal": {
            "input_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ],
               [
                  1,
                  512,
                  7,
                  7
               ]
            ],
            "output_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ],
               [
                  1,
                  512,
                  7,
                  7
               ]
            ],
            "requan_scale_a": 1,
            "requan_zp_a": 0,
            "requan_scale_b": 1,
            "requan_zp_b": 0
         },
         "fp32_sum_sub_group0": {
            "sumsub_group_mode": "add",
            "sumsub_group_b_mux": "vector",
            "input_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ],
               [
                  1,
                  512,
                  7,
                  7
               ]
            ],
            "output_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ]
            ]
         },
         "relu_group": {
            "input_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ]
            ],
            "output_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ]
            ]
         },
         "post_cal": {
            "mul_k": 9.755285728884521,
            "sum_b": -128.0,
            "sumsub_mode": "add",
            "carry_sel": "round",
            "input_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ]
            ],
            "output_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ]
            ]
         }
      },
      "ori_name": "Relu_122",
      "input_batchdim": [
         0,
         0
      ],
      "output_batchdim": [
         0
      ]
   },
   "GlobalAveragePool_123_1": {
      "layer_index": 67,
      "name": "GlobalAveragePool_123_1",
      "operation": "avg_pool2d",
      "device": "npu",
      "pool_size": [
         7,
         7
      ],
      "padding": [
         0,
         0,
         0,
         0
      ],
      "stride": [
         1,
         1
      ],
      "ceil_mode": false,
      "file_list": {
         "input_activation1": "GlobalAveragePool_123_1_input_activation1.npy",
         "input_activation2": "GlobalAveragePool_123_1_input_activation2.npy",
         "output_activation1": "GlobalAveragePool_123_1_output_activation1.npy"
      },
      "previous_layer": [
         "Add_121_1",
         "GlobalAveragePool_123_1_constant1"
      ],
      "next_layer": [
         "Gemm_125"
      ],
      "input_shape": [
         [
            1,
            512,
            7,
            7
         ],
         [
            1,
            1,
            1,
            1
         ]
      ],
      "output_shape": [
         [
            1,
            512,
            1,
            1
         ]
      ],
      "input_dtype": [
         "int8",
         "float32"
      ],
      "output_dtype": [
         "int8"
      ],
      "tensor0_lut": [
         1,
         1,
         1
      ],
      "tensor1_lut": [
         0,
         0,
         0
      ],
      "module_list": {
         "pre_cal": {
            "requan_scale_a": 0.1025085300207138,
            "requan_zp_a": 13.121091842651367,
            "input_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ],
               [
                  1,
                  1,
                  1,
                  1
               ]
            ],
            "output_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ],
               [
                  1,
                  1,
                  1,
                  1
               ]
            ],
            "requan_scale_b": 1,
            "requan_zp_b": 0
         },
         "fp32_mul_group": {
            "mul_group_k_mux": "scalar",
            "act_mode": "others",
            "mul_group_k_scalar": 0.020408162847161293,
            "input_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ],
               [
                  1,
                  1,
                  1,
                  1
               ]
            ],
            "output_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ]
            ]
         },
         "acc_tree_group": {
            "acc_tree_mode": "acc",
            "acc_dim": "kernel",
            "input_shape": [
               [
                  1,
                  512,
                  7,
                  7
               ]
            ],
            "output_shape": [
               [
                  1,
                  512,
                  1,
                  1
               ]
            ]
         },
         "post_cal": {
            "mul_k": 28.519990573921934,
            "sum_b": -128.0,
            "sumsub_mode": "add",
            "carry_sel": "round",
            "input_shape": [
               [
                  1,
                  512,
                  1,
                  1
               ]
            ],
            "output_shape": [
               [
                  1,
                  512,
                  1,
                  1
               ]
            ]
         }
      },
      "ori_name": "GlobalAveragePool_123",
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ]
   },
   "Gemm_125": {
      "layer_index": 68,
      "name": "Gemm_125",
      "operation": "dense",
      "device": "npu",
      "input_dtype": [
         "int8",
         "int8"
      ],
      "output_dtype": [
         "float16"
      ],
      "input_shape": [
         [
            1,
            512,
            1,
            1
         ],
         [
            1000,
            512,
            1,
            1
         ]
      ],
      "output_shape": [
         [
            1,
            1000,
            1,
            1
         ]
      ],
      "quant_info": {
         "input_scale1": 0.03506312519311905,
         "input_zero_point1": 128.0
      },
      "previous_layer": [
         "GlobalAveragePool_123_1",
         "constant_fc_weight"
      ],
      "next_layer": [
         "Gemm_125_reshape_output0"
      ],
      "file_list": {
         "input_activation1": "Gemm_125_input_activation1.npy",
         "input_activation2": "Gemm_125_input_activation2.npy",
         "output_activation1": "Gemm_125_output_activation1.npy",
         "k": "Gemm_125_k.npy",
         "b": "Gemm_125_b.npy"
      },
      "input_batchdim": [
         0,
         -1
      ],
      "output_batchdim": [
         0
      ],
      "activation_type": null,
      "activation_attr": null
   },
   "Gemm_125_reshape_output0": {
      "layer_index": 69,
      "name": "Gemm_125_reshape_output0",
      "operation": "reshape",
      "device": "cpu",
      "input_dtype": [
         "float16"
      ],
      "output_dtype": [
         "float16"
      ],
      "input_shape": [
         [
            1,
            1000,
            1,
            1
         ]
      ],
      "output_shape": [
         [
            1,
            1000
         ]
      ],
      "previous_layer": [
         "Gemm_125"
      ],
      "next_layer": [
         "output1"
      ],
      "file_list": {
         "input_activation1": "Gemm_125_reshape_output0_input_activation1.npy",
         "output_activation1": "Gemm_125_reshape_output0_output_activation1.npy"
      },
      "input_batchdim": [
         0
      ],
      "output_batchdim": [
         0
      ],
      "ori_name": "Gemm_125",
      "nhwc_consistant": true
   }
}